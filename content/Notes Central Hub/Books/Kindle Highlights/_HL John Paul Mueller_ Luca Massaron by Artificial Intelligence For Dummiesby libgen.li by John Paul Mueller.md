---
aliases:
  - John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li
  - >-
tags:
  - kindle-highlights
file-created: 2023-05-07
file-modified: 2023-09-21
note-type: kindle highlights 
description: 
kindle-sync:
  bookId: '25345'
  title: >-
    John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies
    (2021, Wiley) - libgen.li
  author: John Paul Mueller
  highlightsCount: 90
linter-yaml-title-alias: John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li
---

# John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li

## Metadata

* Author: [[John Paul Mueller]]

## Highlights

"You can find the cheat sheet for this book by going to www.dummies.com and searching for Artificial Intelligence For Dummies. Under the title, click Cheat Sheet and look for the one for this book. The cheat sheet contains really neat information, such as the meaning of all those strange acronyms and abbreviations associated with AI, machine learning, and deep learning."  ^ref-32234
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

---
"however, intelligence often follows a process that a computer system can mimic as part of a simulation: Set a goal based on needs or wants. Assess the value of any currently known information in support of the goal. Gather additional information that could support the goal. The emphasis here is on information that could support the goal, rather than information that you know will support the goal. Manipulate the data such that it achieves a form consistent with existing information. Define the relationships and truth values between existing and new information. Determine whether the goal is achieved. Modify the goal in light of the new data and its effect on the probability of success. Repeat Steps 2 through 7 as needed until the goal is achieved (found true) or the possibilities for achieving it are exhausted (found false)."  ^ref-56164
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

---
"TABLE 1-1 The Kinds of Human Intelligence and How AIs Simulate Them"  ^ref-4890
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

Comment: Copy

---
"In order to create, an AI would need to possess self-awareness, which would require intrapersonal intelligence."  ^ref-64380
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

---
"(see “Say What? How the Brain Separates Our Ability to Talk and Write” from John Hopkins University),"  ^ref-53620
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

Comment: Check ref

---
"In humans, oral, aural, and written linguistic intelligence come from different areas of the brain (see “Say What? How the Brain Separates Our Ability to Talk and Write” from John Hopkins University),"  ^ref-19661
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

---
"the first concept that’s important to understand is that AI doesn’t really have anything to do with human intelligence. Yes, some AI is modeled to simulate human intelligence, but that’s what it is: a simulation."  ^ref-7727
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

---
"To pass the Turing test, an AI should have all four previous technologies and possibly integrate other solutions (such as expert systems)."  ^ref-5032
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

---
"The original Turing Test didn’t include any physical contact. Harnad’s Total Turing Test does include physical contact, in the form of perceptual ability interrogation, which means that the computer must also employ both computer vision and robotics to succeed. Here’s a quick overview of other Turing Test alternatives: Reverse Turing Test: A human tries to convince a computer that that the human is not a computer (for example, the Completely Automatic Public Turing Test to Tell Computers and Humans Apart, or CAPTCHA). Minimum Intelligent Signal Test: Only true/false and yes/no questions are given. Marcus Test: A computer program simulates watching a television show, and the program is tested with meaningful questions about the show's content. Lovelace Test 2.0: A test detects AI through examining its ability to create art. Winograd Schema Challenge: This test asks multiple-choice questions in a specific format."  ^ref-2969
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

Comment: alt turing

---
"the solving of a problem in principle is often different from solving it in practice, but you still need a starting point."  ^ref-10996
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

---
"A process is rational if it always does the right thing based on the current information, given an ideal performance measure. In short, rational processes go by the book and assume that the book is actually correct. Human processes involve instinct, intuition, and other variables that"  ^ref-48798
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

---
"HUMAN VERSUS RATIONAL PROCESSES Human processes differ from rational processes in their outcome. A process is rational if it always does the right thing based on the current information, given an ideal performance measure. In short, rational processes go by the book and assume that the book is actually correct. Human processes involve instinct, intuition, and other variables that don’t necessarily reflect the book and may not even consider the existing data. As an example, the rational way to drive a car is to always follow the laws. However, traffic isn’t rational. If you follow the laws precisely, you end up stuck somewhere because other drivers aren’t following the laws precisely. To be successful, a self-driving car must therefore act humanly, rather than rationally."  ^ref-52836
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

Comment: THe human approach to problem solving

---
"some groups view AI as either strong (generalized intelligence that can adapt to a variety of situations) or weak (specific intelligence designed to perform a particular task well). The problem with strong AI is that it doesn’t perform any task well, while weak AI is too specific to perform tasks independently. Even so, just two type classifications won’t do the job even in a general sense."  ^ref-32714
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

Comment: Strong vs weak ai. High level category of generalizability of ai

---
"The four classification types promoted by Arend Hintze (see “Understanding the four types of AI, from reactive robots to self-aware beings” at Conversation.com for details) form a better basis for understanding AI: Reactive machines: The machines you see beating humans at chess or playing on game shows are examples of reactive machines. A reactive machine has no memory or experience upon which to base a decision. Instead, it relies on pure computational power and smart algorithms to re-create every decision every time. This is an example of a weak AI used for a specific purpose. (The “Considering the Chinese Room argument” section of Chapter 5 explains the meaning of a weak AI.) Limited memory: An SD car or autonomous robot can’t afford the time to make every decision from scratch. These machines rely on a small amount of memory to provide experiential knowledge of various situations. When the machine sees the same situation, it can rely on experience to reduce reaction time and to provide more resources for making new decisions that haven’t yet been made. This is an example of the current level of strong AI. Theory of mind: A machine that can assess both its required goals and the potential goals of other entities in the same environment has a kind of understanding that is feasible to some extent today, but not in any commercial form. However, for SD cars to become truly autonomous, this level of AI must be fully developed. An SD car would not only need to know that it must go from one point to another, but also intuit the potentially conflicting goals of drivers around it and react accordingly. (Robot soccer, http://www.cs.cmu.edu/~robosoccer/main/ and https://www.robocup.org/, is another example of this kind of understanding, but at a simple level.) Self-awareness: This is the sort of AI that you see in movies. However, it requires technologies that aren’t even remotely possible now because such a machine would have a sense of both self and consciousness. In addition, instead of merely intuiting the goals of others based on environment and other entity reactions, this type of machine would be able to infer the intent of others based on experiential knowledge."  ^ref-12766
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

Comment: Four types of ai according to arend hintze

---
"However, the desire to create intelligent machines (or, in ancient times, idols) is as old as humans. The desire not to be alone in the universe, to have something with which to communicate without the inconsistencies of other humans, is a strong one."  ^ref-3190
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

Comment: Humans avoid being lonely. Why we create art?

---
"During the summer of 1956, various scientists attended a workshop held on the Dartmouth College campus to do something more. They predicted that machines that could reason as effectively as humans would require, at most, a generation to come about. They were wrong. Only now have we realized machines that can perform mathematical and logical reasoning as effectively as a human (which means that computers must master at least six more intelligences before reaching anything even close to human intelligence)."  ^ref-47004
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

---
"The biggest problem with these early attempts (and still a considerable problem today) is that we don’t understand how humans reason well enough to create any sort of simulation — assuming that a direct simulation is even possible. Consider again the issues surrounding manned flight described earlier in the chapter. The Wright brothers succeeded not by simulating birds but rather by understanding the processes that birds use, thereby creating the field of aerodynamics. Consequently, when someone says that the next big AI innovation is right around the corner and yet no concrete dissertation exists of the processes involved, the innovation is anything but right around the corner."  ^ref-28691
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

Comment: We need to understand principles to replicate and improve an iteration

---
"You still see expert systems in use today (even though they aren’t called that any longer). For example, the spelling and grammar checkers in your application are kinds of expert systems. The grammar checker, especially, is strongly rule based. It pays to look around to see other places where expert systems may still see practical use in everyday applications."  ^ref-10672
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

Comment: Expert  systems

---
"Expert systems first appeared in the 1970s and again in the 1980s as an attempt to reduce the computational requirements posed by AI using the knowledge of experts. A number of expert system representations appeared, including rule based (which use if…then statements to base decisions on rules of thumb), frame based (which use databases organized into related hierarchies of generic information called frames), and logic based (which rely on set theory to establish relationships). The advent of expert systems is important because they present the first truly useful and successful implementations of AI."  ^ref-508
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

Comment: Expert systems

---
"The term AI winter refers to a period of reduced funding in the development of AI. In general, AI has followed a path on which proponents overstate what is possible, inducing people with no technology knowledge at all, but lots of money, to make investments. A period of criticism then follows when AI fails to meet expectations, and, finally, the reduction in funding occurs. A number of these cycles have occurred over the years — all of them devastating to true progress."  ^ref-35355
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

Comment: ai winter represents boom and bust cycles similar to economies?

---
"Machine learning has pitfalls because the computer can learn"  ^ref-43170
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

---
"It’s like educating a baby by showing it how to behave through example. Machine learning has pitfalls because the computer"  ^ref-26599
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

---
"machine learning, a technology that helps computers learn from data. Having a computer learn from data means not depending on a human programmer to set operations (tasks), but rather deriving them directly from examples that show how the computer should behave. It’s like educating a baby by showing it how to behave through example. Machine learning has pitfalls because the computer can learn how to do things incorrectly through careless teaching."  ^ref-638
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

---
"At this time, the most successful solution is deep learning, which is a technology that strives to imitate the human brain. Deep learning is possible because of the availability of powerful computers, smarter algorithms, large datasets produced by the digitalization of our society, and huge investments from businesses such as Google, Facebook, Amazon, and others that take advantage of this AI renaissance for their own businesses."  ^ref-15386
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

Comment: As of today , the current best paradigm for artificial intelligence

---
"Here are just a few of the ways in which you might see AI used: Fraud detection: You get a call from your credit card company asking whether you made a particular purchase. The credit card company isn’t being nosy; it’s simply alerting you to the fact that someone else could be making a purchase using your card. The AI embedded within the credit card company’s code detected an unfamiliar spending pattern and alerted someone to it. Resource scheduling: Many organizations need to schedule the use of resources efficiently. For example, a hospital may have to determine where to put a patient based on the patient’s needs, availability of skilled experts, and the amount of time the doctor expects the patient to be in the hospital. Complex analysis: Humans often need help with complex analysis because there are literally too many factors to consider. For example, the same set of symptoms could indicate more than one problem. A doctor or other expert might need help making a diagnosis in a timely manner to save a patient’s life. Automation: Any form of automation can benefit from the addition of AI to handle unexpected changes or events. A problem with some types of automation today is that an unexpected event, such as an object in the wrong place, can actually cause the automation to stop. Adding AI to the automation can allow the automation to handle unexpected events and continue as if nothing happened. Customer service: The customer service line you call today may not even have a human behind it. The automation is good enough to follow scripts and use various resources to handle the vast majority of your questions. With good voice inflection (provided by AI as well), you may not even be able to tell that you’re talking with a computer. Safety systems: Many of the safety systems found in machines of various sorts today rely on AI to take over the vehicle in a time of crisis. For example, many automatic braking systems (ABS) rely on AI to stop the car based on all the inputs that a vehicle can provide, such as the direction of a skid. Computerized ABS is actually relatively old at 40 years from a technology perspective (see “ABS (Anti-Lock Braking System) — A Brief History Of A 40-Year-Old Life-Saver” at DriveSpark.com for details). Machine efficiency: AI can help control a machine in such a manner as to obtain maximum efficiency. The AI controls the use of resources so that the system doesn’t overshoot speed or other goals. Every ounce of power is used precisely as needed to provide the desired services."  ^ref-31586
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

Comment: Current usage of "mundane" ai

---
"Here are the five tribes of learning: Symbologists: The origin of this tribe is in logic and philosophy. This group relies on inverse deduction to solve problems. Connectionists: This tribe’s origin is in neuroscience, and the group relies on backpropagation to solve problems. Evolutionaries: The evolutionaries tribe originates in evolutionary biology, relying on genetic programming to solve problems. Bayesians: This tribe’s origin is in statistics and relies on probabilistic inference to solve problems. Analogizers: The origin of this tribe is in psychology. The group relies on kernel machines to solve problems."  ^ref-40431
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

Comment: FIve approaches to developing ai

---
"The ultimate goal of machine learning is to combine the technologies and strategies embraced by the five tribes to create a single algorithm (the master algorithm) that can learn anything. Of course, achieving that goal is a long way off. Even so, scientists such as Pedro Domingos at the University of Washington are currently working toward that goal."  ^ref-56613
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

Comment: How we define machine singularity or what we think is the best approach

---
"so creating master algorithms for all five tribes may still not yield the singularity. At this point, you should be amazed at just how much people don’t know about how they think or why they think in a certain manner. Any rumors you hear about AI taking"  ^ref-20680
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

Comment: The singularity is not near yet

---
"creating master algorithms for all five tribes may still not yield the singularity. At this point, you should be amazed at just how much people don’t know about how they think or why they think in a certain manner. Any rumors you hear about AI taking over the world or becoming superior to people are just plain false."  ^ref-40148
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

---
"To discover the future direction of AI, it’s best to ask a computer scientist or data scientist with a strong background in AI research."  ^ref-44485
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

Comment: Look to experts of the field

---
"The size of the computing system is directly proportional to the amount of work you expect the AI to perform."  ^ref-1735
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

Comment: Law of conservation? You need equivalent compute power for a difficult task. Moore's law previously predicted that computing power doubled x years

---
"The knowledge base varies in location and size as well. The more complex the data, the more you can obtain from it, but the more you need to manipulate it as well. You get no free lunch when it comes to knowledge management. The interplay between location and time is also important. A network connection affords you access to a large knowledge base online but costs you in time because of the latency of network connections. However, localized databases, while fast, tend to lack details in many cases."  ^ref-21414
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

Comment: Tradeoffs of on premise vs cloud processing

---
"Defining the Role of Data IN THIS CHAPTER Seeing data as a universal resource Obtaining and manipulating data Looking for mistruths in data Defining data-acquisitions limits Considering data security"  ^ref-59137
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

---
"it’s not a matter of just one to two data collection techniques; collection methods take place on a continuum from fully manual to fully automatic. You also find a focus today on collecting this data ethically — for example, not collecting data that a person hasn’t granted permission for."  ^ref-12227
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

Comment: Data collection techniques live on a spectrum and require ethical means

---
"It also doesn’t pay to collect data in a manner that isn’t secure. The data must be free of bias, uncorrupted, and from a source you know."  ^ref-30404
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

Comment: Qualities of good data collection ingredients

---
"From a technical perspective, big data refers to large and complex amounts of computer data, so large and intricate that applications can’t deal with the data simply by using additional storage or increasing computer power. Big data implies a revolution in data storage and manipulation. It affects what you can achieve with data in more qualitative terms (meaning that in addition to doing more, you can perform tasks better). From a human perspective, computers store big data in different data formats (such as database files and .csv files),"  ^ref-39614
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

Comment: Definition of big data

---
"You can view data as being one of two types, structured and unstructured, depending on how you produce and consume it. Some data has a clear structure (you know exactly what it contains and where to find every piece of data), whereas other data is unstructured (you have an idea of what it contains, but you don't know exactly how it is arranged). Typical examples of structured data are database tables, in which information is arranged into columns, and each column contains a specific type of information. Data is often structured by design. You gather it selectively and record it in its correct place. For example, you might want to place a count of the number of people buying a certain product in a specific column, in a specific table, in a specific database. As with a library, if you know what data you need, you can find it immediately. Unstructured data consists of images, videos, and sound recordings. You may use an unstructured form for text so that you can tag it with characteristics, such as size, date, or content type. Usually you don’t know exactly where data appears in an unstructured dataset because the data appears as sequences of ones and zeros that an application must interpret or visualize. Transforming unstructured data into a structured form can cost lots of time and effort and can involve the work of many people. Most of the data of the big data revolution is unstructured and stored as it is, unless someone renders it structured."  ^ref-60839
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

Comment: Types of data. Structured Vs unstructured. Most mkdern generated data is unstructured

---
"In 1965, Gordon Moore, cofounder of Intel and Fairchild Semiconductor, wrote in an article entitled “Cramming More Components Onto Integrated Circuits,” at IEEE.org, that the number of components found in integrated circuits would double every year for the next decade. At that time, transistors dominated electronics. Being able to stuff more transistors into an Integrated Circuit (IC) meant being able to make electronic devices more capable and useful."  ^ref-39023
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

Comment: Moore's Law

---
"The semiconductor industry calls it Moore’s Law (see http://www.mooreslaw.org/ for details). Doubling did occur for the first ten years, as predicted. In 1975, Moore corrected his statement, forecasting a doubling every two years. Figure 2-1 shows the effects of this doubling."  ^ref-61929
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

---
"FIGURE 2-1: Stuffing more and more transistors into a CPU."  ^ref-27868
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

---
"What matters is that since 1965, the doubling of components every two years has ushered in great advancements in digital electronics that has had far-reaching consequences in the acquisition, storage, manipulation, and management of data. Moore’s Law has a direct effect on data. It begins with smarter devices. The smarter the devices, the more diffusion (as evidenced by electronics being everywhere today). The greater the diffusion, the lower the price becomes, creating an endless loop that drives the use of powerful computing machines and small sensors everywhere. With large amounts of computer memory available and larger storage disks for data, the consequences are an expansion of data availability, such as websites, transaction records, measurements, digital images, and other sorts of data."  ^ref-29716
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

Comment: Data begets stronger requirements which beget more opportunities to generate data.
On Moore's law

---
"The Internet now generates and distributes new data in large amounts. Our current daily data production is estimated to amount to about 2.5 quintillion (a number with 18 zeros) bytes, with the lion’s share going to unstructured data like videos and audios. All this data is related to common human activities, feelings, experiences, and relations. Roaming through this data, an AI can easily learn how reasoning and acting more human-like works."  ^ref-26574
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

Comment: How the internet allows ai t access global human intelligence. I

---
"The human race is now at an incredible intersection of unprecedented volumes of data, generated by increasingly smaller and powerful hardware. The data is also increasingly processed and analyzed by the same computers that the process helped spread and develop. This statement may seem obvious, but data has become so ubiquitous that its value no longer resides only in the information it contains (such as the case of data stored in a firm’s database that allows its daily operations), but rather in its use as a means to create new values. Some people call such data the “new oil.”"  ^ref-38700
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

Comment: Data is the new oil thought

---
"In recent years, AI algorithms have moved to neural networks and, in their most mature form, deep learning. As this methodological passage happened, data turned from being the information processed by predetermined algorithms to becoming what molded the algorithm into something useful for the task. Data turned from being just the raw material that fueled the solution to the artisan of the solution itself, as shown in Figure 2-2. FIGURE 2-2: With the present AI solutions, more data equates to more intelligence. Thus, a photo of some of your kittens has become increasingly useful not simply because of its affective value — depicting your cute little cats — but because it could become part of the learning process of an AI discovering more general concepts, such as what characteristics denote a cat, or understanding what defines cute."  ^ref-50968
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

Comment: VDeep learning performance increases nonlinearly with the volume of data

---
"Algorithms that process words can help Google AI systems understand and anticipate your needs even when you are not expressing them in a set of keywords but in plain, unclear natural language, the language we speak every day (and yes, everyday language is often unclear). If you currently try to pose questions, not just chains of keywords, to the Google search engine, you’ll notice that it tends to answer correctly. Since 2012, with the introduction of the Hummingbird update (read the details in “FAQ: All About The New Google ‘Hummingbird’ Algorithm” at Search Engine Land.com), Google has steadily become better able to understand synonyms and concepts, something that goes beyond the initial data that it acquired, and this is the result of an AI process. A few years after Hummingbird, Google deployed an even more advanced algorithm named RankBrain (“FAQ: All about the Google RankBrain algorithm” at Search Engine Land.com), which learns directly from millions of queries every day and can answer ambiguous or unclear search queries, even expressed in slang or colloquial terms or simply riddled with errors. RankBrain doesn’t service all the queries, but it learns from data how to better answer queries. After its introduction in 2015, it quickly began to handle 15 percent of the engine’s queries, but it won’t replace Hummingbird (see “7 Things You May Not Know About Google’s RankBrain” at Act On.com and “The Rankbrain, Hummingbird, and Search Engine Optimization Fusion” at Connectica.com for details)."  ^ref-17736
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

Comment: Google's AI systems hide in plain sight

---
"The most common data source is from information entered by humans at some point. Even when a system collects shopping-site data automatically, humans initially enter the information."  ^ref-26231
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

Comment: On data sources

---
"Many data sources today rely on input gathered from human sources. Humans also provide manual input."  ^ref-18325
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

Comment: On data sources

---
"Data is also collected from sensors, and these sensors can take almost any form. For example, many organizations base physical data collection, such as the number of people viewing an object in a window, on cellphone detection. Facial recognition software could potentially detect repeat customers. However, sensors can create datasets from almost anything. The weather service relies on datasets created by sensors that monitor environmental conditions such as rain, temperature, humidity, cloud cover, and so on."  ^ref-54894
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

Comment: On data sources

---
"The word reliable seems so easy to define, yet so hard to implement. Something is reliable when the results it produces are both expected and consistent. A reliable data source produces mundane data that contains no surprises; no one is shocked in the least by the outcome."  ^ref-364
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

Comment: Reliable Data. On  data sources

---
"Consequently, data has an aspect of duality. We want reliable, mundane, fully anticipated data that simply confirms what we already know, but the unexpected is what makes collecting the data useful in the first place. Still, you don’t want data that is so far out of the ordinary that it becomes almost frightening to review. Balance needs to be maintained when obtaining data. The data must fit within certain limits (as described in the “Manicuring the Data” section, later in this chapter). It must also meet specific criteria as to truth value (as described in the “Considering the Five Mistruths in Data” section, later in this chapter). The data must also come at expected intervals, and all the fields of the incoming data record must be complete."  ^ref-57147
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

Comment: On data quality and duality

---
"Drop-down list boxes work well for an amazing array of data inputs, and using them ensures that human input into those fields becomes extremely reliable because the human has no choice but to use one of the default entries. Of course, the human can always choose the incorrect entry, which is where double-checks come into play. Some newer applications compare the zip code to the city and state entries to see whether they match. When they don’t match (sometimes it’s just a matter of capitalization), the user is asked again to provide the correct input. This double-check verges on being annoying, but the user is unlikely to see it very often, so it shouldn’t become too annoying."  ^ref-20426
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

Comment: Ensuring data consistency through constraints such as dropdown lists

---
"Using automated data collection Some people think that automated data collection solves all the human input issues associated with datasets. In fact, automated data collection does provide a number of benefits: Better consistency Improved reliability Lower probability of missing data Enhanced accuracy Reduced variance for things like timed inputs Unfortunately, to say that automated data collection solves every issue is simply incorrect. Automated data collection still relies on sensors, applications, and computer hardware designed by humans that provide access only to the data that humans decide to allow. Because of the limits that humans place on the characteristics of automated data collection, the outcome often provides less helpful information than hoped for by the designers. Consequently, automated data collection is in a constant state of flux as designers try to solve the input issues. Automated data collection also suffers from both software and hardware errors present in any computing system, but with a higher potential for soft issues (which arise when the system is apparently working but isn’t providing the desired result) than other kinds of computer-based setups. When the system works, the reliability of the input far exceeds human abilities. However, when soft issues occur, the system often fails to recognize, as a human might, that a problem exists, and therefore the dataset could end up containing more mediocre or even bad data."  ^ref-50237
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

Comment: On using automated data collection still requires human help

---
"collect personal data ethically: Obtaining permission: Some research will require you to be able to identify persons used within a dataset. Going out and grabbing Personally Identifiable Information (PII) isn’t a good way to gather data. For one thing, you can’t be sure that the information is either complete or correct, so any analysis you perform is suspect. For another thing, you could encounter the messy and costly consequences of legal actions. The best way to obtain data with PII is to ask permission. You can find a number of resources online for asking permission, for example at the government level, by finding the right resource, such as “How to Obtain a Consumer’s Authorization before Gaining Access to Personally Identifiable Information (PII).” Using sanitization techniques: Data sanitization involves removing personal information, such as name, address, telephone number, ID, and so on from a dataset so that identifying a particular individual in a dataset becomes impossible. In addition to text and dataset variables, you must consider every kind of data. For instance, if you are working with collections of photos, it is paramount that you take steps to blur faces and remove car plates from images. Oddly enough, if you perform a Google search using sanitization as a key term, you still get many links dealing with cleaning. Adding privacy as another key term helps find the sorts of articles you actually need. Even so, you may find that you’re not the only one who is confused about the process. Avoiding Data Inference: When collecting data, some users will refuse to share personally identifiable information, such as gender and age. One recommendation is to infer this information when a user’s picture or other information is available. Unfortunately, names that are associated with one gender in a particular culture may be assigned to the other gender in other cultures. The problem with age inference is even more profound. For example, a machine learning algorithm will likely infer the wrong age for an albino, which can affect as many as one in 3,000 individuals, depending on the part of the world the data comes from (see details in “Information Bulletin – What is Albinism?” at NOAH.com.) Avoiding generalizations: Many fields of study today try to incorrectly apply statistics and machine learning outcomes, with the result that an individual ends up being mistreated in some manner. It’s essential to remember that statistics apply to groups, not to individuals."  ^ref-48366
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

Comment: On.collecting data ethically

---
"Dealing with missing data"  ^ref-56461
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

Comment: Use as headline. Look at section

---
"Often, someone who makes a decision, essentially answering a question, without all the facts is said to jump to a conclusion. When analyzing data, you have probably jumped to more conclusions than you think because of missing data."  ^ref-9560
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

Comment: Jumping.to.conclusions is a lack of dafa awareness

---
"Essential data missing: A problem can occur when the data collection process doesn’t include all the data needed to answer a particular question. Sometimes you’re better off to actually drop a fact rather than use a considerably damaged fact. Some data missing: Less damaged fields can have data missing in one of two ways, randomly or sequentially, as described here: Randomly missing data is often the result of human or sensor error. Fixing randomly missing data is easiest. You can use a simple median or average value as a replacement. No, the dataset isn’t completely accurate, but it will likely work well enough to obtain a reasonable answer. Sequentially missing data occurs during some type of generalized failure. Fixing sequentially missing data is significantly harder, if not impossible, because you lack any surrounding data on which to base any sort of guess. If you can find the cause of the missing data, you can sometimes reconstruct it."  ^ref-16139
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

Comment: Dealing With poor data

---
"To solve problems efficiently, an AI requires just enough data. Defining the question that you want to answer concisely and clearly helps, as does using the correct algorithm (or algorithm ensemble)."  ^ref-24269
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

Comment: Goldilocks of data volume to answer a question. Too little and you'll fail to represent the situation accurately. Too muc and  you'll get noise

---
"One of the issues that make it hard, if not impossible, to create an AI that actually thinks like a human is that humans can work with mistruths and computers can’t. The best you can hope to achieve is to see the errant data as outliers and then filter it out, but that technique doesn’t necessarily solve the problem because a human would still use the data and attempt to determine a truth based on the mistruths that are there."  ^ref-12117
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

Comment: Humans handle ambiguity

---
"The following sections use a car accident as the main example to illustrate five types of mistruths that can appear in data."  ^ref-65242
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

Comment: Get the five mistruths

---
"Mistruths of commission are those that reflect an outright attempt to substitute truthful information for untruthful information."  ^ref-55119
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

---
"Although it would seem as if mistruths of commission are completely avoidable, often they aren’t. Human tell “little white lies” to save others embarrassment or to deal with an issue with the least amount of personal effort. Sometimes a mistruth of commission is based on errant input or hearsay. In fact, the sources for errors of commission are so many that it really is hard to come up with a scenario where someone could avoid them entirely. All this said, mistruths of commission are one type of mistruth that someone can avoid more often than not."  ^ref-50507
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

---
"Mistruths of omission are those where a person tells the truth in every stated fact, but leaves out an important fact that would change the perception of an incident as a whole."  ^ref-33619
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

---
"Avoiding mistruths of omission is nearly impossible. Yes, people could purposely leave facts out of a report, but it’s just as likely that they’ll simply forget to include all the facts."  ^ref-29563
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

Comment: Omissions are a result of limited memory

---
"Mistruths of perspective occur when multiple parties view an incident from multiple vantage points."  ^ref-22547
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

---
"Perspective Mistruths of perspective occur when multiple parties view an incident from multiple vantage points."  ^ref-21217
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

---
"Perspective is perhaps the most dangerous of the mistruths because anyone who tries to derive the truth in this scenario will, at best, end up with an average of the various stories, which will never be fully correct. A human viewing the information can rely on intuition and instinct to potentially obtain a better approximation of the truth, but an AI will always use just the average, which means that the AI is always at a significant disadvantage. Unfortunately, avoiding mistruths of perspective is impossible because no matter how many witnesses you have to the event, the best you can hope to achieve is an approximation of the truth, not the actual truth."  ^ref-6876
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

Comment: Some opinions or perspectives are worth discarding

---
"The idea of a general truth — one that is true for everyone — is a myth. It doesn’t exist."  ^ref-65471
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

Comment: Subjectivity Of truth

---
"Bias Mistruths of bias occur when someone is able to see the truth but because of personal concerns or beliefs is unable to actually see"  ^ref-10056
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

---
"A problem with bias is that it can be incredibly hard to categorize."  ^ref-48554
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

---
"In many cases, confirming the source of bias becomes important when creating an algorithm designed to avoid a bias source."  ^ref-2319
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

Comment: Understand sources of bias. Add to cognitive bias

---
"Theoretically, avoiding mistruths of bias is always possible. In reality, however, all humans have biases of various types, and those biases will always result in mistruths that skew datasets. Just getting someone to actually look and then see something — to have it register in the person’s brain — is a difficult task. Humans rely on filters to avoid information overload, and these filters are also a source of bias because they prevent people from actually seeing things."  ^ref-57830
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

Comment: Digest

---
"Frame of reference Of the five mistruths, frame of reference need not actually be the result of any sort of error, but one of understanding. A frame-of-reference mistruth occurs when one party describes something, such as an event like an accident, and because a second party lacks experience with the event, the details become muddled or completely misunderstood. Comedy routines abound that rely on frame-of-reference errors."  ^ref-63897
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

---
"Getting one person to understand what a second person is saying can be impossible when the first person lacks experiential knowledge — the frame of reference. Another frame-of-reference mistruth example occurs when one party can’t possibly understand the other."  ^ref-7456
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

---
"The best way to avoid frame-of-reference mistruths is to ensure that all parties involved can develop similar frames of reference."  ^ref-29054
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

---
"According to “Data Never Sleeps” at Domo.com, the world is collecting data at an extraordinary rate every minute. Here are just some examples: Zoom hosts 208,333 participants in meetings. Users post 347,222 Instagram stories. Microsoft Teams connects 52,083 users. Users share 41,666,667 messages on WhatsApp. People make 1,388,889 video/voice calls."  ^ref-42974
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

Comment: On data explosion

---
"Data acquisition can occur in unlimited amounts, but figuring out the right questions to ask can be daunting, if not impossible."  ^ref-2179
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

Comment: on turning information into knowledge

---
"When you combine poorly collected, ill-formed data with algorithms that don’t actually answer your questions, you get output that may actually lead your business in the wrong direction, which is why AI is often blamed for inconsistent or unreliable results. Asking the right question, obtaining the correct data, performing the right processing, and then correctly analyzing the data are all required to make data acquisition the kind of tool you can rely on."  ^ref-36487
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

Comment: On gathering information aka data acquisition

---
"Bias appears in nearly every dataset available today, even custom-created datasets. The dataset is often biased because the collection methods are biased, the analysis methods are biased, and the data itself is biased."  ^ref-43529
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

Comment: On bias. Bias in datasets

---
"Here are some areas in which data becomes purposely biased: Political: Political maneuvering can become the source of data bias. Two groups with opposing opinions will use the same dataset and obtain two completely different outcomes that support their particular perspective. At issue are the records selected and the dataset features used to create an outcome. In other cases, a group will resort to techniques like using bogus respondents in polls (see “Assessing the Risks to Online Polls From Bogus Respondents” from Pew Research.org for details). Medical: When medical groups advertise for people to participate in trials of medications, procedures, and other needs, the group they get often doesn’t represent the population as a whole, so the data is biased. For example, the article “Older Adults, Minorities Underrepresented in COVID-19 Vaccine Trials” at AARP.com points out that the vaccine trials didn’t contain enough minorities and older adults, leading to data bias. Legal: The use of COMPAS to predict the potential for recidivism is another example of data and algorithm bias, as explained in “Injustice Ex Machina: Predictive Algorithms in Criminal Sentencing,” at UCLA Law Review.org. The article points out so many flaws with COMPAS that the best idea might be to start from scratch, because the software is destroying people’s lives at an unprecedented rate. Hiring: The use of datasets and well-rounded algorithms supposedly reduces the risk of bias in hiring and promoting individuals within an organization. According to “All the Ways Hiring Algorithms Can Introduce Bias” at Harvard Business Review.org, the opposite is too often true. The datasets become an amplification of biased hiring practices within an organization or within society as a whole. Other: Any time a dataset and its associated algorithms become influenced by bias, the outcome is less than ideal. The term machine learning fairness presents the idea that the outcome of any analysis should correctly represent the actual conditions within society (see “A Tutorial on Fairness in Machine Learning” at Towards Data Science.comfor details). If the outcome of an analysis doesn’t match the result received afterward, the analysis is flawed and the data usually receives a lion’s share of the blame."  ^ref-3972
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

Comment: On biased data

---
"Botnets are coordinated groups of computers that focus on performing specific tasks, most of them nefarious. This short section focuses on botnets that feed a dataset erroneous data or take over accounts to modify the account information in certain ways. Whatever means is used, whatever the intent, botnets generally corrupt or bias data in ways that cause any kind of analysis to fail. One of the best methods for dealing with these botnets is to sinkhole them — that is, redirect them to a location where they can’t do any harm. The Wired article “Hacker Lexicon: What Is Sinkholing?” provides techniques for performing this task."  ^ref-35782
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

Comment: Sinkholing to take negative and redirect

---
"Advances in AI hint that for some problems, choosing the right amount of data is more important than the right algorithm. For instance, in 2001, two researchers from Microsoft, Banko and Brill, in their memorable paper, “Scaling to Very Very Large Corpora for Natural Language Disambiguation,” demonstrated that if you want a computer to create a model of a language, you don’t need the smartest algorithm in town. After throwing more than one billion words within context at the problem, any algorithms will start performing incredibly well."  ^ref-41588
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

Comment: SOne problems can be sokved through scale and the law of large numbers

---
"However, no matter how much data you have, you still need an algorithm to make it useful."  ^ref-30799
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

Comment: Have a plan?

---
"An algorithm is a procedure that consists of a sequence of operations. Usually, a computer deals with these operations by either finding the correct solution to a problem in a finite time or telling you that no solution exists."  ^ref-60774
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

Comment: On algorithms

---
"Algorithms are all about finding solutions, and the speedier and easier, the better. Algorithms have become hard-coded in the intelligence of humans who devised them, and any machine operating on algorithms cannot but reflect the intelligence embedded into such algorithmic procedures. AI provides the means to simulate the human in processing and solving existing algorithms, but AI can’t replace humans or mimic human creativity in devising new algorithms."  ^ref-50217
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

Comment: Faster the better…ceat using heuristics to trade speed for complexity of analysis ?

---
"People tend to recognize AI when a tool presents a novel approach and interacts with the user in a human-like way. Examples include digital assistants such as Siri, Alexa, Cortana, and Google Assistant. However, certain other common tools, such as GPS routers and specialized planners (like those used to avoid automotive collisions, auto-pilot airplanes, and arrange production plans) don’t even look like AI because they’re too common and taken for granted as they act behind the scenes. In addition, it’s important to consider alternative forms of AI, such as smart thermostats that control the environment based on past usage and current environmental data, and smart garage door openers that automatically detect when you accidentally leave the door open after you leave for work. This is clearly the AI effect, as named and described by Pamela McCorduck, an American author who wrote a notable history of AI, Machines Who Think, in 1979."  ^ref-49777
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

Comment: On Ai effect

---
"The AI effect states that people soon forget about successful, intelligent computer programs, which become silent actors while attention shifts to AI problems that still require resolution. The importance of classic algorithms to AI gets overlooked, and people start fantasizing about AI created from esoteric technology, or they equate it with recent advances, such as machine learning and deep learning."  ^ref-20664
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

Comment: Ai effect is similar to the overton window. We take things for granted and become oversensitized

---
"An algorithm always presents a series of steps, but it doesn’t necessarily perform all these steps to solve a problem (some steps are optional or performed only under specific conditions). A group of related steps is an operation,"  ^ref-52729
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

Comment: On algorithms . Cincept of operation

---
"The scope of algorithms is incredibly large. Operations may involve storing data, exploring it, and ordering or arranging it into data structures. You can find algorithms that solve problems in science, medicine, finance, industrial production and supply, and communication. All algorithms contain sequences of operations to find the correct solution to a problem in a reasonable time (or report back if no solution is found). A subclass of algorithms, heuristics, produce good, but not necessarily perfect, solutions when time is more critical than finding the perfect solution."  ^ref-9509
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

Comment: Digest

---
"AI algorithms distinguish themselves from generic algorithms by solving problems whose resolution is considered typically (or even exclusively) the product of human intelligent behavior. AI algorithms tend to deal with complex problems, which are often part of the NP-complete class of problems (where NP is nondeterministic polynomial time) that humans routinely deal with by using a mix of rational approach and intuition. Here are just a few examples: Scheduling problems and allocating scarce resources Searching routes in complex physical or figurative spaces Recognizing patterns in image vision (versus something like image restoration or image processing) or sound perception Processing language (both text understanding and language translation) Playing (and winning) competitive games"  ^ref-46699
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

Comment: On ai algorithms. Related to algorithms

---
"NP-complete problems distinguish themselves from other algorithmic problems because finding a solution for them in a reasonable time frame isn’t yet possible. NP-complete isn’t the kind of problem that you solve by trying all possible combinations or possibilities. Even if you had computers more powerful than those that exist today, a search for the solution would last almost forever. In a similar fashion, in AI, this kind of problem is called AI-complete."  ^ref-40787
* John Paul Mueller_ Luca Massaron - Artificial Intelligence For Dummies- libgen.li by John
Mueller

Comment: On Np

---
