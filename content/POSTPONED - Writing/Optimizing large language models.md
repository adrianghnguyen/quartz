---
note-type:
  - general
aliases: 
 - Optimizing large language models
---

#status/postponed 

Related to [[Large language models produce human text using big data]]

---

## Optimizing large language models

There are various techniques depending on what we are referring to.

- If we're looking to increase the performance in the sense of token generation, we could refer to the [[Quantization|quantization]] technique.
- If we're talking in the sense that we want the model to perform better, it's referred to as fine tuning - training on a more specialized dataset to improve response accuracy.

- See also [[Fine tuning large language models]]