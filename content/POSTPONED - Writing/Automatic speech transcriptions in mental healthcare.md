---
aliases:
  - Automatic speech transcriptions in mental healthcare
  - ASR in therapy
tags:
  - intelligence/artificial-intelligence
  - society/healthcare
  - psychology/therapy
file-created: 2023-09-06
file-modified: 2023-09-06
note-type:
  - general
description: 
linter-yaml-title-alias: Automatic speech transcriptions in mental healthcare
---

# Automatic speech transcriptions in mental healthcare

#status/postponed

---

Related to [[REF Augmenting Psychotherapy with AI]]

[[Artificial intelligence (AI) in mental healthcare technologies|AI (artificial intelligence) in therapeutic settings]] could be used to do [[automatic speech recognition (ASR)|automatic speech recognition (ASR)]].

> Before NLP can be used to augment clinical care, researchers need to know whether automatic speech recognition systems (ASRs) can transcribe therapy sessions accurately enough that they can then be used to detect therapeutic patterns in real-world clinical settings.

- Early findings seems to indicate that the models need further training but provide a possible option for transcribing therapy sessions.

> It’s also important to make sure the ASR works well for all patient populations, Miner says. For example, the team found that the ASR transcribed female and male patients equally well, but did not look at transcription accuracy for different racial groups, which is an important area for future research, Miner says. A recent [paper](https://5harad.com/papers/asr-disparities.pdf) by a Stanford group led by Sharad Goel found that ASR systems have higher error rates for black people. “That’s clearly concerning,” Miner says. “We need to be doing a better job of making sure that these systems are robust for groups that have been underserved in health care settings.”

- Seems that gender transcriptions for ASR is working fairly well but further research needs to be done on possible racial bias to ensure robustness of underserved minorities
