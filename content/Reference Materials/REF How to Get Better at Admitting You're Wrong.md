---
aliases:
  - How to Get Better at Admitting You are Wrong
  - article on being wrong
tags:
  - reference-material/read-it-later/article
file-created: 2023-05-19
file-modified: 2023-09-03
note-type: article
description: 
author: Arthur C. Brooks
linter-yaml-title-alias: How to Get Better at Admitting You are Wrong
original-title: "How to Get Better at Admitting You're Wrong"
reference: true
source:
  - "https://www.theatlantic.com/family/archive/2021/03/to-get-happier-admit-when-youre-wrong/618245/"
website: The Atlantic
---

 #status/done

# How to Get Better at Admitting You are Wrong

## Personal and linked notes

```dataview
	LIST
	FROM [[]] and !#admin and !#admin/moc
```

---

## How to Get Better at Admitting You're Wrong

> [!Warning] Reference note
> The original source can be found here: <https://www.theatlantic.com/family/archive/2021/03/to-get-happier-admit-when-youre-wrong/618245/>

---

## Article content

%%make it easy to delete under a heading%%
![](Reference%20Materials/Clippings/original.jpg)

*“[How to Build a Life](https://www.theatlantic.com/projects/how-build-life/)***”* is a weekly column by Arthur Brooks, tackling questions of meaning and happiness.*

---

In the late 1950s and early 1960s, the psychologist Henry Murray [asked](https://psycnet.apa.org/record/1964-02238-001) a sample of college sophomores to participate in a seemingly innocuous experiment in which they would write their “personal philosophy of life,” including their core values and guiding principles, and then engage in a civil debate with a young lawyer about the merits of the philosophy. He did not tell the participants that the lawyer had been instructed to interrogate them and rip their philosophy to shreds in a “vehement, sweeping, and personally abusive” way. They used techniques Murray had developed in vetting intelligence agents during World War II.

The results were fairly predictable. Murray found that the students were generally intensely uncomfortable at having their views attacked in this way. Most hated it and remembered the experiment negatively even years later. One of the student participants was Ted Kaczynski, who went on to become the Unabomber. Noting that his revenge fantasies and belief in the evils of society began during his college years, some have [linked his philosophy](https://www.theatlantic.com/magazine/archive/2000/06/harvard-and-the-making-of-the-unabomber/378239/) to the Murray experiment. (Others [dispute](https://www.theatlantic.com/magazine/archive/2000/09/letters/378379/) this idea.)

[From the June 2000 issue: Harvard and the making of the Unabomber](https://www.theatlantic.com/magazine/archive/2000/06/harvard-and-the-making-of-the-unabomber/378239/)

But not all of Murray’s participants recall the experiment as a horrible experience. In his book [*Think Again*](https://www.indiebound.org/book/9781984878106), Adam Grant, a psychologist at the University of Pennsylvania, notes that most of the students had a negative experience. But Grant’s research also showed that a few notable outliers said they liked it—at least one found it *fun*—likely because they were forced to rethink their beliefs.

This latter group might have been onto something important. Rethinking your opinions—and changing your views when your facts are proved wrong or someone makes a better argument—can make your life better. It can make you more successful, less anxious, and happier.

When it comes to the idea that we are wrong, or that we should change our opinions, we are incredibly adept at resisting. Grant writes that we possess an astonishing array of cognitive biases telling us, *You are right—disregard all evidence to the contrary*. These include [[confirmation bias]] (we focus on and preferentially remember information that reinforces our beliefs); anchoring bias (we over-rely on one key piece of information—usually the first one we received); the [[Overconfidence is a slow and insidious killer|illusion of validity]] (we overestimate the accuracy of our own judgments and perceptions); and many other related tendencies. These biases are like a crocodile-filled moat around the fortress of our beliefs. They turn us into hermit kings, convinced that any counterarguments that break through our walls will bring us misery.

[From the September 2018 issue: The cognitive biases tricking your brain](https://www.theatlantic.com/magazine/archive/2018/09/cognitive-bias/565775/)

But as Grant argues, being closed off to being proved wrong or to having our beliefs challenged has huge costs. Leaders who surround themselves with yes-men have been shown to make costly—and sometimes catastrophic—mistakes. One classic example is the Bay of Pigs debacle, in which President John F. Kennedy’s insular cabinet failed to challenge his misguided instincts. Or consider the political punditocracy that assumed Donald Trump couldn’t possibly be a serious threat to Hillary Clinton in the 2016 presidential election, and never revised those assumptions. If your goal is to find the truth, admitting you are wrong and changing your beliefs based on new facts makes you better off in the end. This is a primary feature of what philosophers call “[epistemic humility](https://www.sciencedirect.com/science/article/pii/S0039368115000990?casa_token=btaYMaFPOlQAAAAA:SjbdM2FdJkYEoGFe9Sy68gfsQvrNDrYZv3RT1-K0tk9kzZwEG8F4H47eyfuWEjERcqhaO50X4VkK).”

And while it might not feel easy or fun at first, epistemic humility, like all humility, has clear happiness benefits. In one [2016 study](https://www.tandfonline.com/doi/abs/10.1080/17439760.2015.1127991) in *The* *Journal of Positive Psychology*, researchers created a humility score by asking people about their openness to advice, their honesty about their own strengths and weaknesses, and whether they tended to be excited about a friend’s accomplishments. They found that humility was negatively associated with depression and anxiety, and positively associated with happiness and life satisfaction. Furthermore, they found that humility buffers the negative impact of stressful life events.

As is often the case with social science, the data on humility and happiness reinforce what philosophers have long taught. Around the turn of the fifth century, Saint Augustine [gave](https://books.google.com/books?id=bKNK8-7mt5kC&pg=PA446&lpg=PA446&dq=%22the+first+part+is+humility;+the+second+humility;+the+third+humility:+and+this+I+would+continue+to+repeat+as+often+as+you+might+ask+direction%22&source=bl&ots=vBZJIB1quN&sig=ACfU3U2ao8oL2s0cmgTuw1lE0t6lTn9eag&hl=en&sa=X&ved=2ahUKEwjhrf6Q2truAhV2MlkFHR8wBJAQ6AEwCHoECAgQAg#v=onepage&q=%22the%20first%20part%20is%20humility%3B%20the%20second%20humility%3B%20the%20third%20humility%3A%20and%20this%20I%20would%20continue%20to%20repeat%20as%20often%20as%20you%20might%20ask%20direction%22&f=false) a student three pieces of life advice: “The first part is humility; the second, humility; the third, humility: and this I would continue to repeat as often as you might ask direction.” About a thousand years earlier, the Buddha [taught](https://mettarefuge.wordpress.com/2010/12/07/the-buddha-on-attachment-to-views-and-disputations/) in the *Dutthatthaka Sutta* that attachment to one’s views and opinions is a particular source of [[Human suffering stems from personal attachment|human suffering]]. These ancient ideas could not be more relevant to modern life.

The humility to admit when we are wrong and to change our beliefs can lead us to greater success and happiness. But with our defenses arrayed against these virtues, we need a battle plan to alter our way of thinking and acting. Here are four strategies you might want to add to your arsenal:

### 1\. Turn the hermit king against himself

The hermit king walls himself in against admitting a mistake or changing his mind because he fears that doing so will make him look stupid or incompetent. Thus, left to your limbic tendencies, you will fight to the death for even doomed ideas. But this tendency is itself based on an error.

[Read: Your flaws are probably more attractive than you think they are](https://www.theatlantic.com/health/archive/2019/01/beautiful-mess-vulnerability/579892/)

In a [2015 study](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0143723) in the scientific journal *PLOS One*, researchers compared scientists’ reactions to being informed that their findings “don’t replicate”—that is, they are probably not correct—a common problem in academia. It would be no surprise if scientists, like most people, got defensive when contradicted in this way, or even doubled down on their original results. But the researchers found that this sort of behavior was more harmful to the scientists’ reputation than simply admitting they were wrong. The message for the hermit king is this: If you are wrong, the best way to save face is to admit it.

### 2\. Welcome contradiction

One of the best ways to combat a destructive tendency is to adopt an [“opposite signal” strategy](https://www.theatlantic.com/family/archive/2020/11/sedentary-pandemic-life-happiness/617142/). For example, when you are sad, often the last thing you want to do is see others, but this is precisely what you should do. When your [[Embrace contradiction with an open mind|ideas are threatened]] and you feel defensive, actively reject your instinct to defend yourself, and become more open instead. When someone says, “You are wrong,” respond with, “Tell me more.” Make friends who think differently than you and challenge your assumptions—and whose assumptions you challenge. Think of this as building your “team of rivals,” the phrase the historian Doris Kearns Goodwin [used](https://www.npr.org/2012/11/15/165220138/doris-kearns-goodwin-on-lincoln-and-his-team-of-rivals) to describe Abraham Lincoln’s cabinet, which, unlike Kennedy’s, challenged him relentlessly. If this sounds like torture, it is all the more urgent that you try it.

### 3\. Don’t Document all your beliefs

Sociopolitical forces today can make humility feel especially dangerous, and even foolish. Social media has stunted our ability to reinvent our thinking, because our ideas are increasingly cumulative: Every opinion we’ve ever posted online is memorialized. With such a well-documented history of beliefs, [[Cognitive flexibility is adapting our thoughts and beliefs as appropriate|changing your mind]] on something important or controversial can feel like weakness and open you up to [[Keeping things private and away from social media|public criticism]].

[Read: This article won’t change your mind](https://www.theatlantic.com/science/archive/2017/03/this-article-wont-change-your-mind/519093/)

The solution to this is to take most of your opinions off the electronic grid. Share your views with people you know and trust, but not with strangers on Twitter and Facebook. Sharing your views with total strangers on social media is a weird conceit to begin with—that people you don’t know should care about your opinions. And realistically, there’s no opinion you can preserve in internet amber right now that will benefit you in five years.

### 4\. Start small

Let’s suppose that you want the benefits of changing your mind. Getting started is hard, especially if the view you want to change is something huge, like your religious beliefs or your political ideology. It’s better to start with smaller ideas such as your fashion choices, or even your sports allegiances. Reconsider the things you have long taken for granted, and assess them as dispassionately as you can. Then, with these low stakes, change.

[Read: The subtle mindset shift that could radically change the way you see the world](https://www.theatlantic.com/family/archive/2021/02/dalai-lama-gentle-transgressive-individuality-happiness/617901/)

The point is not to deal in trivialities. [Research](https://www.goodreads.com/book/show/43261127-tiny-habits) on goal setting clearly shows that starting small teaches you how to change and break habits. Then, you can scale this self-knowledge up to the bigger areas of your life in which, you secretly suspect, you might just be wrong. At that point, with your new skills in hand, the adventure of finding truth starts.

If you master these techniques, there might be critics who say you are a flip-flopper, or wishy-washy. To deal with this, take a lesson from the great economist Paul Samuelson. In 1948, Samuelson published what might be the most celebrated [economics textbook](https://www.mheducation.com/highered/product/economics-samuelson-nordhaus/M9780073511290.toc.html) of all time. As the years went by and he updated the book, he changed his estimate of the inflation level that was tolerable for the health of the macroeconomy: First, he said 5 percent was acceptable; then, in later editions, 3 percent and 2 percent, prompting the Associated Press to run an article titled “Author Should Make Up His Mind.” In a television interview after Samuelson was awarded the Nobel Prize in 1970, he gave his [answer](https://quoteinvestigator.com/2011/07/22/keynes-change-mind/) to the charge: “When events change, I change my mind. What do you do?”

In pursuit of happiness, you can do this too. When events change, you acquire new information, or someone simply makes a great argument, go ahead and change your mind, and do it openly. It might seem like a tough ask at first. But trust me: It will go from hard to fun. You have nothing to lose but your moat.
