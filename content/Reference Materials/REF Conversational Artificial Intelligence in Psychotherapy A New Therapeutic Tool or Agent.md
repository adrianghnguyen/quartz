---
dg-publish: true
aliases:
  - "Conversational Artificial Intelligence in Psychotherapy: A New Therapeutic Tool or Agent?"
tags:
  - reference-material/read-it-later/article
note-type: 
description: 
file-created: 2023-10-24
file-modified: 2023-10-24
author: Manuel  Trachsel
linter-yaml-title-alias: "Conversational Artificial Intelligence in Psychotherapy: A New Therapeutic Tool or Agent?"
original-title: "Conversational Artificial Intelligence in Psychotherapy: A New Therapeutic Tool or Agent?"
reference: true
source:
  - "https://www.tandfonline.com/doi/full/10.1080/15265161.2022.2048739"
website: Taylor & Francis
---
 #status/done

# Conversational Artificial Intelligence in Psychotherapy: A New Therapeutic Tool or Agent?

> [!Warning] Reference note
> The original source can be found here: https://www.tandfonline.com/doi/full/10.1080/15265161.2022.2048739

Related to [[Artificial intelligence (AI) in mental healthcare technologies|AI in mental healthcare]] and [[Conversational AI for therapy|AI therapist chatbot]]

> **Conversational artificial intelligence (CAI)** presents many opportunities in the psychotherapeutic landscape—such as therapeutic support for people with mental health problems and without access to care. The adoption of CAI poses many risks that need in-depth ethical scrutiny. The objective of this paper is to complement current research on the ethics of AI for mental health by proposing a holistic, ethical, and epistemic analysis of CAI adoption. First, we focus on the question of whether CAI is rather a tool or an agent. This question serves as a framework for the subsequent ethical analysis of CAI focusing on topics of (self-) knowledge, (self-)understanding, and relationships. Second, we propose further conceptual and ethical analysis regarding human-AI interaction and argue that CAI cannot be considered as an equal partner in a conversation as is the case with a human therapist. Instead, CAI’s role in a conversation should be restricted to specific functions.

- The greatest potential of CAI lies in providing care for vulnerable groups such as the elderly, adolescence, and people who do not receive treatment for several reasons (e.g., fear of stigmatization, financial problems, or preference for other solutions than traditional treatments)
- The article argues for the following thesis:
	- "CAI should not be understood as a tool merely implementing evidence-based therapies nor as a digital therapist, but as a new artifact that can change our interactions, concepts, epistemic field, and normative requirements and whose status on the spectrum between a tool and a therapist or an agent respectively, needs to be defined."
	- Something which may change the paradigm of the mental health landscape?

Long story short, the article argues that this is a new type of conversation that needs to be explored and there's further research to be found, and it's not similar to the traditional kind of conversation between a therapist and a patient. It's more useful to look at it as a novel type of epistemic exchange instead of trying to mimic human conversation. Both that implies that we need to develop new norms, a norm of conditions under which we can analyze this.

I don't think this article was very useful, except saying that this is a brand new type of tool which needs to be explored under a new type of context.